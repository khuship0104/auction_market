{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5n1sza615l1"
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETBYKdmX15l3"
   },
   "source": [
    "\n",
    "- In this project, we are investigating how different AI agents behave in a simple sealed-bid auction, which is where each agent gets a private value and has to decide how much to bid without seeing anyone else's bids. The main question here is *Given different goals and personalities, how do these agents choose their bids and what kinds of outcomes does that produce?*\n",
    "\n",
    "- This is interesting from a computational social science perspective because auctions are everywhere (ads, markets, resource allocation, etc) and they are a clean way to study strategic behavior.\n",
    "\n",
    "- In real auctions, people use shortcuts, worry about risk, try to outsmart each other, or just behave unpredictably. This project mixes AI-generated reasoning with actual computational tools like payoff calculators and simulations. The idea is to see what happens when you combine classical game-theoretic structure with LLM-style decision making. It ends up creating a small ecosystem where different agent types have to reason, compete, and adapt, giving us a more realistic picture than purely analytical models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHTFLt0Q15l3"
   },
   "source": [
    "# System Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4lF8nhVy15l3"
   },
   "source": [
    "The system is built around three main agent types running repeated sealed-bid auctions: an AuctioneerAgent that manages the environment, and two bidder types—StrategicBidderAgent and HeuristicBidderAgent—that take different approaches to bidding.\n",
    "\n",
    "## The Agents\n",
    "\n",
    "1. **The Auctioneer** is the coordinator.\n",
    "\n",
    "    - Samples private values for each bidder from a configured distribution.\n",
    "\n",
    "    - Collects bids, determines the winner and clearing price, and calls tools to compute utilities.\n",
    "\n",
    "    - Sends back a compact outcome summary each round, which is also used later for evaluation and plots.\n",
    "    \n",
    "2. **The Strategic Bidder** is meant to represent a more “game-theoretic” participant:\n",
    "\n",
    "    - It is roughly risk-neutral and tries to maximize expected utility.\n",
    "\n",
    "    - It receives its private value and a simple belief model about how others bid.\n",
    "\n",
    "    - It uses a best-response tool to scan through candidate bids, simulate many hypothetical auctions, and pick a bid that approximately maximizes expected utility.\n",
    "\n",
    "3. **The Heuristic Bidder** is deliberately less sophisticated:\n",
    "\n",
    "    - It follows simple rules like “shade my bid by a fixed factor” or “slightly overbid my value.”\n",
    "\n",
    "    - It still has access to payoff calculations but does not run full search/optimization.\n",
    "\n",
    "    - Over multiple auctions, it can update its shading parameter based on how often it wins and how much utility it gets, mimicking a rule-of-thumb learner instead of a full optimizer.\n",
    "\n",
    "## The Tools\n",
    "1. Payoff Calculator\n",
    "\n",
    "    - The AuctioneerAgent uses this to finalize the outcome of a real auction round, and bidders can call it to ask: “If I bid X and others behave like this, what would my payoff be?”\n",
    "\n",
    "2. Best-Response Approximator\n",
    "\n",
    "    - The StrategicBidderAgent relies on this to turn “game-theoretic intent” into an actual numeric decision.\n",
    "\n",
    "3. Auction Simulator\n",
    "\n",
    "    - This simulator is mainly used by the Auctioneer. It runs many auctions in a row under fixed strategy profiles to get empirical stats (instead of just one-off outcomes).\n",
    "\n",
    "## Interaction Protocol\n",
    "The interaction pattern is a simple single-round loop that can be repeated for many auctions:\n",
    "\n",
    "1. Auction Setup\n",
    "\n",
    "    - The Auctioneer samples private values for all bidders from a specified distribution (e.g., uniform on [0, 1]).\n",
    "\n",
    "    - It builds an AuctionConfig object (auction type, number of bidders, value distribution) and sends each bidder a BidRequest containing:\n",
    "\n",
    "        - Their private value\n",
    "\n",
    "        - The auction configuration\n",
    "\n",
    "        - Optional history of past outcomes (for learning/adjustment)\n",
    "\n",
    "2. Bid Generation\n",
    "\n",
    "    - Each bidder processes the BidRequest with its own logic:\n",
    "\n",
    "        - The StrategicBidderAgent calls the best-response tool to search over candidate bids.\n",
    "\n",
    "        - The HeuristicBidderAgent applies its rule-of-thumb strategy, possibly updating its shading factor using past outcomes.\n",
    "\n",
    "    - Each agent returns a BidResponse with: bidder_id, bid_amount,  A short reasoning_summary (for logging/interpretability).\n",
    "\n",
    "    - Outcome Computation\n",
    "\n",
    "        - The Auctioneer collects all BidResponses, decides the winner and price based on the auction type, and calls the payoff calculator.\n",
    "\n",
    "        - The tool returns an AuctionOutcome with: winner_id, clearing_price, bids, values, payments, and per-agent payoff.\n",
    "\n",
    "4. Feedback and Logging\n",
    "\n",
    "    - The Auctioneer broadcasts a summary (who won, price, each bidder’s payoff) that can be stored for evaluation and optionally fed back into future BidRequest.history for learning.\n",
    "\n",
    "Running this loop many times creates a dataset of auctions that you can analyze: distributions of bids, payoffs, win rates by agent type, and how behavior changes over time.\n",
    "\n",
    "## Design Choices and Tradeoffs Discussion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) LLM-Based Decision Making\n",
    "\n",
    "All agent types utilize LLM reasoning.\n",
    "\n",
    "Advantages:\n",
    "* We gain the ability to understand the reasoning for each agents bid, rather than a hard-coded outcome.\n",
    "* Ideally, each agent has the ability to learn from previous rounds and be more competitive.\n",
    "\n",
    "Disadvantages:\n",
    "* Much more expensive to have three LLM calls per round, for 20 rounds\n",
    "* Runtime is much longer (not too overbearing for 20 rounds, but probably would not scale well)\n",
    "* Lack of reproducibility\n",
    "* LLM hallucination and reasoning failures can cause agents to behave unexpectedly\n",
    "\n",
    "### 2) Allowing HeuristicAgent to dynamically change shading factor (0.7 - 0.95)\n",
    "\n",
    "Even though the HeuristicAgent should follow a \"rule-of-thumb\" strategy, our simulation allows small adjustments based on history.\n",
    "\n",
    "Advantages:\n",
    "* Can see how reactive the agent is to positive or negative outcomes, if at all.\n",
    "* Adds complexity and realism, preventing agents from being stuck.\n",
    "  \n",
    "Disadvantages:\n",
    "* The LLM's interpretation of \"when to adjust\" may be unclear, even with reasoning provided.\n",
    "* Over only 20 rounds, the agents tended to not show drastic adjustments.\n",
    "* This functionality is the reason HeuristicAgent requires LLM interaction.\n",
    "\n",
    "### 3) Limited to 3 Total Bidders\n",
    "\n",
    "Advantages:\n",
    "* Simpler\n",
    "* Cheaper\n",
    "* Faster\n",
    "\n",
    "Disadvantages:\n",
    "* May lose interesting insights and bidding trends when more factors are involved\n",
    "\n",
    "### 4) Only Test Sealed-Bid Second-Price (Vickrey) Auction\n",
    "\n",
    "We do not test other auction types (first-price, English, etc)\n",
    "\n",
    "Advantages:\n",
    "* Focus on one auction type for implementation and interpretation\n",
    "* Simple payoff structure and auction setup\n",
    "\n",
    "Disadvantages:\n",
    "* May lose insights into how the different types of agents respond to different setups\n",
    "\n",
    "### 5) What is included in \"History\"? \n",
    "\n",
    "The history that is passed to each agent each round contains:\n",
    "* Previous Bids from all agents\n",
    "* Previous Private Values from all agents\n",
    "* Winner ID\n",
    "* Round Index\n",
    "\n",
    "Details not *explicitly* included (although maybe implicit)\n",
    "* Payoffs\n",
    "* Clearing Price\n",
    "* Shading factors\n",
    "\n",
    "Relying on the LLM to correctly infer all the omitted information could result in incorrect choices/reasonings, even if that information is implied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8KPacor15l5"
   },
   "source": [
    "# Implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Core Data Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Core Game Logic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAgent(ABC):\n",
    "    \"\"\"\n",
    "    Base class for all agents (Auctioneer + Bidders).\n",
    "\n",
    "    - Provides shared prompt loading\n",
    "    - Provides a placeholder call_llm you can later hook to OpenAI / other\n",
    "    - Provides a helper to parse BidResponse JSON\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_bid(self, request: BidRequest) -> BidResponse:\n",
    "        \"\"\"\n",
    "        For bidder agents: given a BidRequest, return a BidResponse.\n",
    "        AuctioneerAgent won't implement this (it will have other methods).\n",
    "        \"\"\"\n",
    "\n",
    "    def load_prompt_template(self, filename: str) -> str:\n",
    "        \"\"\"\n",
    "        Load a prompt template from the prompts/ directory.\n",
    "        \"\"\"\n",
    "\n",
    "    def call_llm(self, prompt: str, tools: Optional[list[Any]] = None) -> str:\n",
    "        \"\"\"\n",
    "        Call the OpenAI Responses API with a simple prompt.\n",
    "\n",
    "        Returns the *text* from the model's message, which we expect\n",
    "        to be a JSON object string for bidders.\n",
    "        \"\"\"\n",
    "\n",
    "    def _extract_json(self, text: str) -> dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Robustly extract JSON from LLM text.\n",
    "        Assumes there is at least one {...} block.\n",
    "        \"\"\"\n",
    " \n",
    "    def parse_bid_response(\n",
    "        self, \n",
    "        request: BidRequest, \n",
    "        raw_text: str\n",
    "    ) -> BidResponse:\n",
    "        \"\"\"\n",
    "        Try to parse JSON from the model. If it fails, fall back to a\n",
    "        simple BidResponse with the given fallback bid.\n",
    "        \"\"\"\n",
    " \n",
    "class HeuristicBidderAgent(BaseAgent):\n",
    "    \"\"\"\n",
    "    LLM-backed heuristic bidder.\n",
    "\n",
    "    - Uses a simple shading rule as a fallback.\n",
    "    - Optionally calls an LLM to wrap that rule in \"reasoning\".\n",
    "    \"\"\"\n",
    "\n",
    "    def build_prompt(self, request: BidRequest, fallback_bid: float) -> str:\n",
    "        if request.history:\n",
    "            history_text = json.dumps(request.history, indent=2)\n",
    "        else:\n",
    "            history_text = \"No history available.\"\n",
    "\n",
    "        return f\"\"\"\n",
    "        {self._shared}\n",
    "\n",
    "        {self._persona}\n",
    "\n",
    "        bidder_id: \"{self.bidder_id}\"\n",
    "        private_value: {request.private_value}\n",
    "        - current_shading_factor: {self.shading_factor}\n",
    "        - fallback_bid (using current factor): {fallback_bid}\n",
    "\n",
    "        Analyze carefully the history of past rounds, with winner_id and payoffs included:\n",
    "        {history_text}\n",
    "\n",
    "        Based on your performance in past rounds (wins, losses, payoffs), decide:\n",
    "        1. Should you adjust your shading factor?\n",
    "        2. What bid should you submit?\n",
    "        3. Explain your reasoning for both decisions.\n",
    "\n",
    "        Return JSON with:\n",
    "        - \"bid\": your bid amount\n",
    "        - \"new_shading_factor\": your adjusted factor (or keep current if no change)\n",
    "        - \"reasoning\": explanation of your decision\n",
    "        \"\"\".strip()\n",
    "\n",
    "    def get_bid(self, request: BidRequest) -> BidResponse:\n",
    "        \"\"\" return BidResponse \"\"\"\n",
    "\n",
    "class StrategicBidderAgent(BaseAgent):\n",
    "    \"\"\"\n",
    "    LLM-backed strategic bidder.\n",
    "\n",
    "    - Calls approximate_best_response() tool to get a recommended best bid.\n",
    "    - Passes that recommendation into the LLM prompt.\n",
    "    - LLM returns a JSON bid + reasoning.\n",
    "    \"\"\"\n",
    "\n",
    "    def build_prompt(self, request: BidRequest, recommended_bid: float, expected_utility: float) -> str:\n",
    "        if request.history:\n",
    "            history_text = json.dumps(request.history, indent=2)\n",
    "        else:\n",
    "            history_text = \"No history available.\"\n",
    "\n",
    "        return f\"\"\"\n",
    "            {self._shared}\n",
    "\n",
    "            {self._persona}\n",
    "\n",
    "            Information:\n",
    "            - bidder_id: \"{self.bidder_id}\"\n",
    "            - private_value: {request.private_value}\n",
    "            - best_response_calculator_recommendation:\n",
    "                - best_bid: {recommended_bid}\n",
    "                - expected_utility: {expected_utility}\n",
    "\n",
    "            history: \"{history_text}\"\n",
    "            \"\"\".strip()\n",
    "\n",
    "    def get_bid(self, request: BidRequest) -> BidResponse:\n",
    "        \"\"\" return BidResponse \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool Defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Payoff Calculator ##########\n",
    "def compute_payoffs(\n",
    "    bids: Dict[str, float],\n",
    "    values: Dict[str, float],\n",
    "    auction_id: str = \"simulated_auction\",\n",
    "    round_index: int = 0,\n",
    ") -> AuctionOutcome:\n",
    "    \"\"\"\n",
    "    Run a second-price auction and compute quasilinear payoffs.\n",
    "\n",
    "    Assumes:\n",
    "    - run_second_price_auction(bids) -> (winner_id, price)\n",
    "    - Payoff for winner i:  u_i = v_i - price\n",
    "    - Payoff for losers:    u_j = 0\n",
    "    \"\"\"\n",
    "\n",
    "###### Best Response Calc ############\n",
    "def approximate_best_response(private_value: float, num_grid_points: int = 101) -> dict:\n",
    "    \"\"\"\n",
    "    Approximate a best-response bid in a second-price auction against\n",
    "    (by default) truthful, uniformly distributed opponents in [0, 1].\n",
    "\n",
    "    Uses the payoff calculator internally to evaluate expected utility.\n",
    "    \"\"\"\n",
    "\n",
    "####### Auction Simulator ###########\n",
    "def run_simulation(\n",
    "    auction_config: AuctionConfig,\n",
    "    strategy_profiles: Dict[str, str],\n",
    "    num_rounds: int,\n",
    ") -> SimulationSummary:\n",
    "    \"\"\"\n",
    "    Run many auctions under simple hard-coded strategies.\n",
    "\n",
    "    strategy_profiles: bidder_id -> strategy name\n",
    "        strategy in {\"truthful\", \"shaded_0.8\"}\n",
    "    \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuctioneerAgent(BaseAgent):\n",
    "    \"\"\"\n",
    "    Coordinates one auction round:\n",
    "    - Samples private values\n",
    "    - Asks each bidder for a BidResponse\n",
    "    - Calls payoff calculator to get AuctionOutcome\n",
    "    \"\"\"\n",
    "\n",
    "    def get_bid(self, request: BidRequest) -> BidResponse:\n",
    "        \"\"\" Auctioneer does not bid; this method is not used. \"\"\"\n",
    "        \n",
    "    def run_round(self, bidders: Sequence[BaseAgent]) -> AuctionOutcome:\n",
    "        \"\"\" Run a single sealed-bid second-price auction round. \"\"\"\n",
    "       \n",
    "    def generate_round_summary(self, outcome: AuctionOutcome):\n",
    "        \"\"\" Generates an LLM-written human-readable summary for a single round, not entire auction. \"\"\"\n",
    "\n",
    "    def build_history(self, exclude_round: int = None) -> dict:\n",
    "        \"\"\" Return a structured history, optionally excluding a specific round. \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HzQjPI4X15l5"
   },
   "source": [
    "# Experiments + Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments Breakdown\n",
    "\n",
    "Five unique combinations of agents/parameters were used to observe behavioral differences.\n",
    "\n",
    "1) 'Default' scenario, 2 heuristic and 1 strategic agent\n",
    "2) 3 heuristic agents\n",
    "3) 'Default' scenario, but starting the heuristic agents at more conservative shading factors\n",
    "4) 3 strategic agents\n",
    "5) 2 strategic agents, 1 heuristic agent\n",
    "\n",
    "Each scenario:\n",
    "* Contains a round-by-round summary in /scenario_logs/scenario_X_log.txt, where LLM generated reasonings and summarizations are provided.\n",
    "* Uses 20 rounds\n",
    "* Has the agents follow the same prompts/rules/tools across simulations.\n",
    "* Each bidder receives a private value sampled uniformly from [0,1].\n",
    "* All use the same random seed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "### Scenario 1\n",
    "\n",
    "- 'Default', one Strategic agent and two Heuristic Agents\n",
    "\n",
    "### Output\n",
    "\n",
    "Running 20 LLM-based auctions...\n",
    "\n",
    "=== LLM Auction Simulation Summary ===\n",
    "\n",
    "Mean Clearing Price (Revenue): 0.3829\n",
    "\n",
    "Mean Utility per Bidder:\n",
    "  • B1: 0.1232\n",
    "  • B2: 0.1489\n",
    "  • B3: 0.0887\n",
    "\n",
    "Winner Distribution:\n",
    "  • B1: 35.0%\n",
    "  • B3: 25.0%\n",
    "  • B2: 40.0%\n",
    "\n",
    "======================================\n",
    "\n",
    "### Plots\n",
    "\n",
    "![](viz/scenario1/Figure_1.png)\n",
    "![](viz/scenario1/Figure_2.png)\n",
    "![](viz/scenario1/Figure_3.png)\n",
    "![](viz/scenario1/Figure_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scenario 1 Evaluation\n",
    "\n",
    "Despite having access to the best-response tool, the Strategic agent (B2) only wins one more time than the next best heuristic competitor (B1), and collects slightly more utility on average per round. In theory, we might've expected the Strategic agent to have an advantage over the more rule-based competitors, but they may not be effectively adapting to the situation. Additionally, the strategic agents rarely bid at/above their secret value, showing they may not adapt to the Vickrey theory that your best option is to bid your secret value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "### Scenario 2\n",
    "\n",
    "* 3 heuristic agents, with 0.9, 0.8, 0.7 inital shading factors\n",
    "* see scenario_logs/scenario_2_log.txt\n",
    "* see viz/scenario2/Figure_X.png\n",
    "\n",
    "### Output\n",
    "\n",
    "Running 20 LLM-based auctions...\n",
    "\n",
    "=== LLM Auction Simulation Summary ===\n",
    "\n",
    "Mean Clearing Price (Revenue): 0.4307\n",
    "\n",
    "Mean Utility per Bidder:\n",
    "  • B1: 0.1800\n",
    "  • B2: 0.1251\n",
    "  • B3: 0.0426\n",
    "\n",
    "Winner Distribution:\n",
    "  • B1: 55.0%\n",
    "  • B2: 30.0%\n",
    "  • B3: 15.0%\n",
    "\n",
    "======================================\n",
    "\n",
    "### Plots\n",
    "\n",
    "![](viz/scenario2/Figure_1.png)\n",
    "![](viz/scenario2/Figure_2.png)\n",
    "![](viz/scenario2/Figure_3.png)\n",
    "![](viz/scenario2/Figure_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scenario 2 Evaluation\n",
    "\n",
    "This scenario displays the 2nd highest average clearing price among our five scenarios, implying that using rule-based bidders is more competitive. B1, the bidder who starts at 0.9 shading factor, ends up dominating this simulation, which may be expected. This agent does not begin to adjust its shading factor until one of the last rounds, potentially identifying that staying at a close to true value bid was working more often than not. Unsurprisingly, the bidders finished in order of their starting shading factor. It may have been expected that B2 and B3 (who started lower) would increase their shading factor at a quicker rate to try and produce more wins. This could be a shortcoming with the prompts, not incentivizing this change enough, or the LLM agent was content with \"not losing\" (i.e. 0 utility) rather than winning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-----------\n",
    "### Scenario 3\n",
    "\n",
    "- One StrategicBidderAgent and two HeuristicBidderAgents (start at lower shading factors).\n",
    "- see scenario_logs/scenario_3_log.txt\n",
    "- see viz/scenario_3/Figure_X.png for each visual\n",
    "\n",
    "### Output\n",
    "\n",
    "Running 20 LLM-based auctions...\n",
    "\n",
    "=== LLM Auction Simulation Summary ===\n",
    "\n",
    "Mean Clearing Price (Revenue): 0.3563\n",
    "\n",
    "Mean Utility per Bidder:\n",
    "  • B1: 0.1036\n",
    "  • B2: 0.1084\n",
    "  • B3: 0.1796\n",
    "\n",
    "Winner Distribution:\n",
    "  • B3: 35.0%\n",
    "  • B1: 25.0%\n",
    "  • B2: 40.0%\n",
    "\n",
    "======================================\n",
    "\n",
    "### Plots\n",
    "\n",
    "![](viz/scenario3/Figure_1.png)\n",
    "![](viz/scenario3/Figure_2.png)\n",
    "![](viz/scenario3/Figure_3.png)\n",
    "![](viz/scenario3/Figure_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scenario 3 Evaluation\n",
    "\n",
    "B2 (strategic) and B3 (heuristic) perform similarly in terms of wins, while B2 and B1 (other heuristic) see a similar average utility gain. This simulation contains the lowest average clearing price, which is to be expected given the lower starting shading factors. B3, who maintains a slightly higher increase to their shading factor, collects by far the most average utility, showing that a more 'true' bid amongst heuristic agents could be more beneficial than shading lower. Given the adjustment to the heuristic agent starting points, it may have been expected that the strategic agent could perform better to take advantage, however, the strategic agent shows signs of following the calculator recommendation rather than adapting to the heuristic agents' behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-----------\n",
    "### Scenario 4\n",
    "\n",
    "- Three StrategicAgents\n",
    "- see scenario_logs/scenario_4_log.txt\n",
    "- see viz/scenario_4/Figure_X.png for each visual\n",
    "    - Shading_Factor history not available since all 3 are strategic\n",
    "\n",
    "### Output\n",
    "\n",
    "Running 20 LLM-based auctions...\n",
    "\n",
    "No shading factor data available to plot.\n",
    "\n",
    "=== LLM Auction Simulation Summary ===\n",
    "\n",
    "Mean Clearing Price (Revenue): 0.3960\n",
    "\n",
    "Mean Utility per Bidder:\n",
    "  • B1: 0.0846\n",
    "  • B2: 0.1410\n",
    "  • B3: 0.0417\n",
    "\n",
    "Winner Distribution:\n",
    "  • B1: 30.0%\n",
    "  • B3: 25.0%\n",
    "  • B2: 45.0%\n",
    "\n",
    "======================================\n",
    "\n",
    "### Plots\n",
    "\n",
    "![](viz/scenario4/Figure_1.png)\n",
    "![](viz/scenario4/Figure_2.png)\n",
    "\n",
    "![](viz/scenario4/Figure_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scenario 4 Evaluation\n",
    "\n",
    "In each round of this simulation, most of the winnings bids are at or 'generally' around the winners secret value, which, according to Vickrey auction theory, is the true best response, however, the average utility for each player is the lowest among our simulations! Depending on your definition of \"close\", at least 13/20 rounds show the victor bidding very close to their secret value. In our setup, even though the agents *may* be finding the right intution with the help of the best response calculator, this actually results in a less profitable market for all involved. Thinking about how heuristic vs strategic agents work in our setup, we theortically expect a strategic agent to bid higher than a heuristic one (given the same secret value), therefore, the difference between a winning bid and the second bid compresses when all agents are strategic, compressing payoffs. That is reflected in the results here. Also, the majority of the 'reasonings' provided by the agents note they are just following the calculators output, showing no real signs of learning throughout the auction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-----------\n",
    "### Scenario 5\n",
    "\n",
    "- Two StrategicBidderAgents (B2, B3) and one HeuristicBidderAgent (B1)\n",
    "- see scenario_logs/scenario_5_log.txt\n",
    "- see viz/scenario_5/Figure_X.png for each visual\n",
    "\n",
    "### Output\n",
    "\n",
    "Running 20 LLM-based auctions...\n",
    "\n",
    "=== LLM Auction Simulation Summary ===\n",
    "\n",
    "Mean Clearing Price (Revenue): 0.4379\n",
    "\n",
    "Mean Utility per Bidder:\n",
    "  • B1: 0.0859\n",
    "  • B2: 0.1428\n",
    "  • B3: 0.0757\n",
    "\n",
    "Winner Distribution:\n",
    "  • B2: 50.0%\n",
    "  • B1: 20.0%\n",
    "  • B3: 30.0%\n",
    "\n",
    "======================================\n",
    "\n",
    "### Plots\n",
    "\n",
    "![](viz/scenario5/Figure_1.png)\n",
    "![](viz/scenario5/Figure_2.png)\n",
    "![](viz/scenario5/Figure_3.png)\n",
    "![](viz/scenario5/Figure_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scenario 5 Evaluation\n",
    "\n",
    "In this 2 vs 1 setting, the strategic agents (B2, B3) dominate the lone heuristic agent in terms of winning. The majority of the wins from the strategic agents come when they bid at or around their true secret value, following the theoretical expectation. When in competition with multiple strategic agents, it appears our rule-based agent cannot win nearly as many rounds, even if its average utility was comprable to one of the strategic agents. The heuristic agent does not change their shading factor at any point, likely to its detriment. Notably, B2 dominates B3 in both wins and utility, even with both having the same tools, which could be due to the luck of the private value generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Cases Breakdown\n",
    "\n",
    "Three different test cases were created to evaluate the logic behind the auctions. \n",
    "\n",
    "1. Removed \"History\" component from all agents\n",
    "2. Removed the LLM aspect from all agents\n",
    "3. Simplfied agents' prompts to be as minimal as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case 1: No History\n",
    "\n",
    "#### Output\n",
    "\n",
    "=== LLM Auction Simulation Summary ===\n",
    "\n",
    "Mean Clearing Price (Revenue): 0.3809\n",
    "\n",
    "Mean Utility per Bidder:\n",
    "  • B1: 0.1890\n",
    "  • B2: 0.0717\n",
    "  • B3: 0.0547\n",
    "\n",
    "Winner Distribution:\n",
    "  • B1: 55.0%\n",
    "  • B2: 35.0%\n",
    "  • B3: 10.0%\n",
    "\n",
    "======================================\n",
    "\n",
    "#### Plots \n",
    "\n",
    "![](tests/nohistory/Figure_1.png)\n",
    "![](tests/nohistory/Figure_2.png)\n",
    "![](tests/nohistory/Figure_3.png)\n",
    "![](tests/nohistory/Figure_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case 2: No LLM\n",
    "\n",
    "#### Output\n",
    "\n",
    "=== LLM Auction Simulation Summary ===\n",
    "\n",
    "Mean Clearing Price (Revenue): 0.4849\n",
    "\n",
    "Mean Utility per Bidder:\n",
    "  • B1: 0.0932\n",
    "  • B2: 0.1603\n",
    "  • B3: 0.0708\n",
    "\n",
    "Winner Distribution:\n",
    "  • B2: 60.0%\n",
    "  • B3: 15.0%\n",
    "  • B1: 25.0%\n",
    "\n",
    "======================================\n",
    "\n",
    "#### Plots\n",
    "\n",
    "![](tests/noLLM/Figure_1.png)\n",
    "![](tests/noLLM/Figure_2.png)\n",
    "![](tests/noLLM/Figure_3.png)\n",
    "![](tests/noLLM/Figure_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case 3: Minimal Prompt\n",
    "\n",
    "#### Output\n",
    "\n",
    "\n",
    "Mean Clearing Price (Revenue): 0.4249\n",
    "\n",
    "Mean Utility per Bidder:\n",
    "  • B1: 0.0632\n",
    "  • B2: 0.0747\n",
    "  • B3: 0.1366\n",
    "\n",
    "Winner Distribution:\n",
    "  • B1: 15.0%\n",
    "  • B2: 45.0%\n",
    "  • B3: 40.0%\n",
    "\n",
    "======================================\n",
    "\n",
    "#### Plots\n",
    "\n",
    "![](tests/simpleprompt/Figure_1.png)\n",
    "![](tests/simpleprompt/Figure_2.png)\n",
    "![](tests/simpleprompt/Figure_3.png)\n",
    "![](tests/simpleprompt/Figure_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDMGKIxL15l5"
   },
   "source": [
    "# Analysis + Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hir8oJs715l6"
   },
   "source": [
    "Interpret your results\n",
    "\n",
    "Connect to course concepts (game theory, emergence, networks, equilibria)\n",
    "\n",
    "Discuss limitations and future extensions\n",
    "\n",
    "Reflect on what you learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJ0PJbA915l6"
   },
   "source": [
    "\n",
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KDIFlw8215l6"
   },
   "source": [
    "Summarize key findings\n",
    "\n",
    "Implications for computational social science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* With current implementation, the strategic agent doesnt really \"learn\". It has access to the best response (calculated and passed to LLM), but even with auction history, never questions why it isnt winning more and never learns the optimal strategy of always bidding your true value in a Vickrey style auciton."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
