{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5n1sza615l1"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETBYKdmX15l3"
      },
      "source": [
        "\n",
        "- In this project, we are investigating how different AI agents behave in a simple sealed-bid auction, which is where each agent gets a private value and has to decide how much to bid without seeing anyone else's bids. The main question here is *Given different goals and personalities, how do these agents choose their bids and what kinds of outcomes does that produce?*\n",
        "\n",
        "- This is interesting from a computational social science perspective because auctions are everywhere (ads, markets, resource allocation, etc) and they are a clean way to study strategic behavior.\n",
        "\n",
        "- In real auctions, people use shortcuts, worry about risk, try to outsmart each other, or just behave unpredictably. This project mixes AI-generated reasoning with actual computational tools like payoff calculators and simulations. The idea is to see what happens when you combine classical game-theoretic structure with LLM-style decision making. It ends up creating a small ecosystem where different agent types have to reason, compete, and adapt, giving us a more realistic picture than purely analytical models.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHTFLt0Q15l3"
      },
      "source": [
        "# System Design"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lF8nhVy15l3"
      },
      "source": [
        "The system is built around three main agent types running repeated sealed-bid auctions: an AuctioneerAgent that manages the environment, and two bidder types—StrategicBidderAgent and HeuristicBidderAgent—that take different approaches to bidding.\n",
        "\n",
        "## The Agents\n",
        "\n",
        "1. **The Auctioneer** is the coordinator.\n",
        "\n",
        "    - Samples private values for each bidder from a configured distribution.\n",
        "\n",
        "    - Collects bids, determines the winner and clearing price, and calls tools to compute utilities.\n",
        "\n",
        "    - Sends back a compact outcome summary each round, which is also used later for evaluation and plots.\n",
        "    \n",
        "2. **The Strategic Bidder** is meant to represent a more “game-theoretic” participant:\n",
        "\n",
        "    - It is roughly risk-neutral and tries to maximize expected utility.\n",
        "\n",
        "    - It receives its private value and a simple belief model about how others bid.\n",
        "\n",
        "    - It uses a best-response tool to scan through candidate bids, simulate many hypothetical auctions, and pick a bid that approximately maximizes expected utility.\n",
        "\n",
        "3. **The Heuristic Bidder** is deliberately less sophisticated:\n",
        "\n",
        "    - It follows simple rules like “shade my bid by a fixed factor” or “slightly overbid my value.”\n",
        "\n",
        "    - It still has access to payoff calculations but does not run full search/optimization.\n",
        "\n",
        "    - Over multiple auctions, it can update its shading parameter based on how often it wins and how much utility it gets, mimicking a rule-of-thumb learner instead of a full optimizer.\n",
        "\n",
        "## The Tools\n",
        "1. Payoff Calculator\n",
        "\n",
        "    - The AuctioneerAgent uses this to finalize the outcome of a real auction round, and bidders can call it to ask: “If I bid X and others behave like this, what would my payoff be?”\n",
        "\n",
        "2. Best-Response Approximator\n",
        "\n",
        "    - The StrategicBidderAgent relies on this to turn “game-theoretic intent” into an actual numeric decision.\n",
        "\n",
        "3. Auction Simulator\n",
        "\n",
        "    - This simulator is mainly used by the Auctioneer. It runs many auctions in a row under fixed strategy profiles to get empirical stats (instead of just one-off outcomes).\n",
        "\n",
        "## Interaction Protocol\n",
        "The interaction pattern is a simple single-round loop that can be repeated for many auctions:\n",
        "\n",
        "1. Auction Setup\n",
        "\n",
        "    - The Auctioneer samples private values for all bidders from a specified distribution (e.g., uniform on [0, 1]).\n",
        "\n",
        "    - It builds an AuctionConfig object (auction type, number of bidders, value distribution) and sends each bidder a BidRequest containing:\n",
        "\n",
        "        - Their private value\n",
        "\n",
        "        - The auction configuration\n",
        "\n",
        "        - Optional history of past outcomes (for learning/adjustment)\n",
        "\n",
        "2. Bid Generation\n",
        "\n",
        "    - Each bidder processes the BidRequest with its own logic:\n",
        "\n",
        "        - The StrategicBidderAgent calls the best-response tool to search over candidate bids.\n",
        "\n",
        "        - The HeuristicBidderAgent applies its rule-of-thumb strategy, possibly updating its shading factor using past outcomes.\n",
        "\n",
        "    - Each agent returns a BidResponse with: bidder_id, bid_amount,  A short reasoning_summary (for logging/interpretability).\n",
        "\n",
        "    - Outcome Computation\n",
        "\n",
        "        - The Auctioneer collects all BidResponses, decides the winner and price based on the auction type, and calls the payoff calculator.\n",
        "\n",
        "        - The tool returns an AuctionOutcome with: winner_id, clearing_price, bids, values, payments, and per-agent payoff.\n",
        "\n",
        "4. Feedback and Logging\n",
        "\n",
        "    - The Auctioneer broadcasts a summary (who won, price, each bidder’s payoff) that can be stored for evaluation and optionally fed back into future BidRequest.history for learning.\n",
        "\n",
        "Running this loop many times creates a dataset of auctions that you can analyze: distributions of bids, payoffs, win rates by agent type, and how behavior changes over time.\n",
        "\n",
        "## Design Choices and Tradeoffs Discussion\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8KPacor15l5"
      },
      "source": [
        "# Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgR4hsKb15l5"
      },
      "source": [
        "Show key code components\n",
        "\n",
        "Demonstrate tool definitions\n",
        "\n",
        "Include example interactions\n",
        "\n",
        "Show state management"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzQjPI4X15l5"
      },
      "source": [
        "# Experiments + Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwJ-x1yl15l5"
      },
      "source": [
        "Present multiple scenarios or experiments\n",
        "\n",
        "Include visualizations where appropriate\n",
        "\n",
        "Show agent reasoning (chain-of-thought outputs)\n",
        "\n",
        "Report evaluation results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDMGKIxL15l5"
      },
      "source": [
        "# Analysis + Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hir8oJs715l6"
      },
      "source": [
        "Interpret your results\n",
        "\n",
        "Connect to course concepts (game theory, emergence, networks, equilibria)\n",
        "\n",
        "Discuss limitations and future extensions\n",
        "\n",
        "Reflect on what you learned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "kieran quick thoughts:\n",
        "\n",
        "- the heuristic agent LLM's seem reluctant to change their shading factor, even with different iterations of expliicit instruction. They also never (from my observation) use a factor below their starting 0.8, at worst keeping it the same. By the end of the auction, both heuristic agents have their final shading factor around 0.9 (sometimes exceeding, even against explicit instructions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJ0PJbA915l6"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDIFlw8215l6"
      },
      "source": [
        "Summarize key findings\n",
        "\n",
        "Implications for computational social science"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
